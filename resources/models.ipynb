{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNQuV7l5TGWsi6JkyTGLGG5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khP6NWrdKWSk","executionInfo":{"status":"ok","timestamp":1670280728863,"user_tz":480,"elapsed":42733,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}},"outputId":"e5753f95-78d6-44b0-a5ad-8aab3150fb9b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["!pip install scanpy --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZFSNox2KiKN","executionInfo":{"status":"ok","timestamp":1670280772985,"user_tz":480,"elapsed":21148,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}},"outputId":"b1c0625d-e01a-45ae-d504-2893e9e84488"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 2.0 MB 4.2 MB/s \n","\u001b[K     |████████████████████████████████| 9.4 MB 34.5 MB/s \n","\u001b[K     |████████████████████████████████| 88 kB 7.2 MB/s \n","\u001b[K     |████████████████████████████████| 96 kB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 295 kB 43.1 MB/s \n","\u001b[K     |████████████████████████████████| 965 kB 53.4 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 62.9 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n","\u001b[?25h  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7bo5YGlE7wI6","executionInfo":{"status":"ok","timestamp":1670297937928,"user_tz":480,"elapsed":401,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","from torch.autograd import Variable\n","import anndata as ad\n","import numpy as np\n","import os\n","from argparse import Namespace\n","config = Namespace(\n","    N_GENES = 13431,\n","    N_PEAKS = 116465,\n","    N_CHANNELS = 32,\n","    MAX_SEQ_LEN_GEX = 1500,\n","    MAX_SEQ_LEN_ATAC = 15000\n",")"]},{"cell_type":"code","source":["adata_gex = ad.read_h5ad(\"drive/MyDrive/Colab_Notebooks/CPSC532S/final_project/data/GEX_processed.h5ad\")"],"metadata":{"id":"xDWcM83eKMAJ","executionInfo":{"status":"ok","timestamp":1670280859961,"user_tz":480,"elapsed":83697,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["adata_atac = ad.read_h5ad(\"drive/MyDrive/Colab_Notebooks/CPSC532S/final_project/data/ATAC_processed.h5ad\")"],"metadata":{"id":"HyD0b7IGp412","executionInfo":{"status":"ok","timestamp":1670299230560,"user_tz":480,"elapsed":158249,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def get_chr_index(adata_atac):\n","  r\"\"\"\n","  Output row indices for each chromosome for each chromosome\n","  Parameters\n","  ----------\n","  adata_atac\n","      annData for ATAC\n","  Returns\n","  -------\n","  chr_index\n","      Dictionary of indices for each chromosome\n","  \"\"\"\n","  row_name = adata_atac.var.index\n","  chr_name = [c.split(\"-\")[0] for c in row_name]\n","  lst = np.unique(chr_name) # names for chromosome\n","\n","  chr_index = dict()\n","  for i in range(len(lst)):\n","    index = [a for a, l in enumerate(chr_name) if l == lst[i]]\n","    if lst[i] not in chr_index:\n","      chr_index[lst[i]]=index\n","\n","  return chr_index"],"metadata":{"id":"rcYnPeRzsPLH","executionInfo":{"status":"ok","timestamp":1670299312864,"user_tz":480,"elapsed":671,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["## Write cnn modules for gex modalities\n","class gexCNN(nn.Module):\n","    \"\"\"customized  module\"\"\"\n","    #argument index is the poisition for each choromosome\n","    def __init__(self, kernel_size):\n","        super(gexCNN, self).__init__()\n","\n","        # Conv layer\n","        self.in_channels = 1 \n","        self.out_channels = config.N_CHANNELS\n","        self.kernel_size = kernel_size   \n","        self.stride = 10 # TO CHANGE \n","        self.padding = 10 # TO CHANGE\n","        self.pool_size = 2\n","        self.pool_stride = 1\n","        self.convs = nn.Sequential(\n","            nn.Conv1d(in_channels = self.in_channels, \n","                      out_channels = self.out_channels, \n","                      kernel_size = self.kernel_size,\n","                      stride = self.stride,\n","                      padding = self.padding),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size = self.pool_size,\n","                         stride = self.pool_stride)\n","        )\n","\n","        # # FC layer\n","        # self.conv_out_features = int((config.N_GENES + 2*self.padding - self.kernel_size) / self.stride + 1)\n","        # self.fc_in_features = int((self.conv_out_features - self.pool_size) / self.pool_stride + 1) * self.out_channels\n","        # self.fc_out_feature = 300\n","        # self.fc = nn.Linear(in_features = self.fc_in_features, out_features = self.fc_out_feature) \n","\n","    def forward(self, x):\n","        r\"\"\"  \n","        Generate ATAC embeddings\n","        \n","        Parameters\n","        ----------\n","        x\n","            Pre-processed GEX data (batch_size x 1 x N_GENES)\n","        \n","        Returns\n","        -------\n","        gex_embed\n","            GEX embeddings of a batch (batch_size x seq_len x dim_size)\n","        \"\"\"\n","        gex_embed = self.convs(x)\n","        # gex_embed = torch.flatten(gex_embed, 1)\n","        # gex_embed = self.fc(gex_embed)\n","        return gex_embed.transpose(1,2)"],"metadata":{"id":"FlJMBCpbKIEa","executionInfo":{"status":"ok","timestamp":1670299297021,"user_tz":480,"elapsed":677,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Test for gexCNN()\n","x = torch.tensor(np.asarray(adata_gex.layers['log_norm'][:5].todense())).unsqueeze(1) # 5 cells\n","print(x.size())\n","model = gexCNN(kernel_size = 10)\n","print(model(x).size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fd0OvPg3PGo","executionInfo":{"status":"ok","timestamp":1670299299488,"user_tz":480,"elapsed":356,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}},"outputId":"12b6e85c-e56e-4684-c605-6ea9d3b9a265"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 1, 13431])\n","torch.Size([5, 1344, 32])\n"]}]},{"cell_type":"code","source":["# Write cnn modules for atac modalities\n","class atacCNN(nn.Module):\n","    #argument index is the poisition for each choromosome\n","    def __init__(self, index, kernel_size):\n","        super(atacCNN, self).__init__()\n","        self.index = index\n","        \n","        # Conv layer\n","        self.in_channels = 1 \n","        self.out_channels = config.N_CHANNELS\n","        self.kernel_size = kernel_size   \n","        self.stride = 10 # TO CHANGE \n","        self.padding = 10 # TO CHANGE\n","        self.pool_size = 2\n","        self.pool_stride = 1\n","        self.convs = nn.Sequential(\n","            nn.Conv1d(in_channels = self.in_channels, \n","                      out_channels = self.out_channels, \n","                      kernel_size = self.kernel_size,\n","                      stride = self.stride,\n","                      padding = self.padding),\n","            nn.ReLU(),\n","            nn.MaxPool1d(kernel_size = self.pool_size,\n","                         stride = self.pool_stride)\n","        )\n","\n","\n","    def forward(self, x):\n","        r\"\"\"  \n","        Generate ATAC embeddings\n","        \n","        Parameters\n","        ----------\n","        x\n","            Pre-processed ATAC data (batch_size x 1 x N_PEAKS)\n","        \n","        Returns\n","        -------\n","        atac_embed\n","            ATAC embeddings of a batch (batch_size x seq_len x dim_size)\n","        \"\"\"\n","        atac_embed = []\n","        for chr in self.index.keys(): \n","            idx = self.index[chr]\n","            x_chr = x[:,:,idx]\n","            x_chr = self.convs(x_chr.float())\n","            atac_embed.append(x_chr)\n","        atac_embed = torch.cat(atac_embed, dim = 2)\n","        return atac_embed.transpose(1,2)"],"metadata":{"id":"LUWvJUcpKIHe","executionInfo":{"status":"ok","timestamp":1670299301722,"user_tz":480,"elapsed":2,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Test for ATAC_CNN()\n","x = torch.tensor(np.asarray(adata_atac.layers['log_norm'][:5].todense())).unsqueeze(1) # 5 cells\n","print(x.size())\n","index = get_chr_index(adata_atac)\n","model = atacCNN(kernel_size = 50, index = index)\n","print(model(x).size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orbL3zsTqYPy","executionInfo":{"status":"ok","timestamp":1670299369081,"user_tz":480,"elapsed":2020,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}},"outputId":"3c869af8-a808-41a0-8236-7c95868be822"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 1, 116465])\n","torch.Size([5, 11566, 32])\n"]}]},{"cell_type":"code","source":["class MultimodalAttention(nn.Module):\n","    def __init__(self):\n","        super(MultimodalAttention, self).__init__()\n","        self.nhead_gex = 1\n","        self.nhead_atac = 4\n","        self.nhead_multi = 4\n","        self.nlayer_gex = 1\n","        self.nlayer_atac = 1\n","        self.nlayer_multi = 1\n","\n","        self.encoder_layer_gex = nn.TransformerEncoderLayer(d_model = config.N_CHANNELS, nhead = self.nhead_gex)\n","        self.transformer_encoder_gex = nn.TransformerEncoder(self.encoder_layer_gex, num_layers = self.nlayer_gex)\n","        # self.linear_gex = nn.Linear(in_features = config.MAX_SEQ_LEN_GEX, out_features = 1)\n","\n","        self.encoder_layer_atac = nn.TransformerEncoderLayer(d_model = config.N_CHANNELS, nhead = self.nhead_atac)\n","        self.transformer_encoder_atac = nn.TransformerEncoder(self.encoder_layer_atac, num_layers = self.nlayer_atac)\n","        # self.linear_atac = nn.Linear(in_features = config.MAX_SEQ_LEN_ATAC, out_features = 1)\n","\n","        self.encoder_layer_multi = nn.TransformerEncoderLayer(d_model = config.N_CHANNELS, nhead = self.nhead_multi)\n","        self.transformer_encoder_multi = nn.TransformerEncoder(self.encoder_layer_multi, num_layers = self.nlayer_multi)\n","    \n","\n","    def forward(self, gex_embed, atac_embed):\n","      r\"\"\"  \n","      Incorporate two self-attention and one cross-attention module\n","\n","      Parameters\n","      ----------\n","      gex_embed\n","          GEX embeddings of a batch (batch_size x seq_len_gex x dim_size)\n","      atac_embed\n","          ATAC embeddings of a batch (batch_size x seq_len_atac x dim_size)\n","\n","      Returns\n","      -------\n","      ## TO FILL\n","      \"\"\"\n","      seq_len_gex = gex_embed.size()[1]\n","      seq_len_atac = atac_embed.size()[1]\n","\n","      gex_context = self.transformer_encoder_gex(gex_embed)\n","      atac_context = self.transformer_encoder_atac(atac_embed)\n","      print(gex_context.size())\n","      print(atac_context.size())\n","\n","      # Average self-attention fragment representation\n","      gex_out_0 = gex_context.mean(dim = 1)\n","      atac_out_0 = atac_context.mean(dim = 1)\n","\n","      multi_embed = torch.cat((gex_context, atac_context), dim = 1)\n","      multi_context = self.transformer_encoder_multi(multi_embed)\n","      print(multi_context.size())\n","      \n","      multi_context_gex = multi_context[:, :seq_len_gex, :]\n","      multi_context_atac = multi_context[:, seq_len_gex:, :]\n","\n","      # Average cross-attention fragment representation\n","      gex_out_1 = multi_context_gex.mean(dim = 1)\n","      atac_out_1 = multi_context_atac.mean(dim = 1)\n","\n","      return gex_out_0, gex_out_1, atac_out_0, atac_out_1"],"metadata":{"id":"2cTz8oUD4aGx","executionInfo":{"status":"ok","timestamp":1670301453424,"user_tz":480,"elapsed":352,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["index = get_chr_index(adata_atac)\n","\n","x_gex = torch.tensor(np.asarray(adata_gex.layers['log_norm'][:5].todense())).unsqueeze(1) # 5 cells\n","x_atac = torch.tensor(np.asarray(adata_atac.layers['log_norm'][:5].todense())).unsqueeze(1) # 5 cells\n","\n","gex_cnn = gexCNN(kernel_size = 10)\n","atac_cnn = atacCNN(kernel_size = 20, index = index)\n","multi_attention = MultimodalAttention()\n","\n","gex_embed = gex_cnn(x_gex)\n","atac_embed = atac_cnn(x_atac)\n","\n","gex_out_0, gex_out_1, atac_out_0, atac_out_1 = multi_attention(gex_embed, atac_embed)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bKfe5KqplRBE","executionInfo":{"status":"ok","timestamp":1670301460534,"user_tz":480,"elapsed":3155,"user":{"displayName":"Ning Shen","userId":"14865340626844030320"}},"outputId":"a23ab174-62f6-45fe-e618-aa3a08013219"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([5, 1344, 32])\n","torch.Size([5, 11635, 32])\n","torch.Size([5, 12979, 32])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"GPTMaJt6mIL1"},"execution_count":null,"outputs":[]}]}